{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“‚ 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import os\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ§  2. Load the Road Rage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Load the pre-trained road rage detection model\n",
    "model = load_model('road_rage_detection_model2.h5')\n",
    "print(\"Pretrained Road Rage Model Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ¥ 3. Live Road Rage Detection with Frame Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Function for real-time road rage detection & saving only violence frames\n",
    "def live_road_rage_detection(model, video_path, output_dir, buffer_size=30, smoothing_window_size=5, violence_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Perform real-time road rage detection on a video stream and save frames labeled as violence.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Pretrained deep learning model\n",
    "    - video_path: Path to the video file (or use 0 for webcam)\n",
    "    - output_dir: Directory to save frames with detected violence\n",
    "    - buffer_size: Number of frames to process in a sequence for prediction\n",
    "    - violence_threshold: Threshold for classifying violence (default = 0.6)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ðŸ“Œ Extract the video name without the extension\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    \n",
    "    # ðŸ“Œ Create a directory for storing detected frames\n",
    "    video_output_dir = os.path.join(output_dir, video_name)\n",
    "    os.makedirs(video_output_dir, exist_ok=True)\n",
    "\n",
    "    # ðŸ“Œ Initialize video capture\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_buffer = []  # Stores frames for batch processing\n",
    "    predictions_buffer = collections.deque(maxlen=smoothing_window_size)  # Stores recent predictions\n",
    "    frame_count = 0  # Track frame numbers\n",
    "    stored_frame_indices = set()  # Keep track of saved frames to avoid duplicates\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # ðŸ“Œ Resize the frame to match model input size (150x150)\n",
    "        frame_resized = cv2.resize(frame, (150, 150))\n",
    "        frame_buffer.append(frame_resized)\n",
    "\n",
    "        # ðŸ“Œ Perform prediction once we have enough frames\n",
    "        if len(frame_buffer) == buffer_size:\n",
    "            input_data = np.array(frame_buffer).reshape((1, buffer_size, 150, 150, 3)) / 255.0\n",
    "            prediction = model.predict(input_data)[0][0]\n",
    "\n",
    "            # ðŸ“Œ Apply threshold to determine if road rage violence is present\n",
    "            is_violence = 1 if prediction > violence_threshold else 0\n",
    "            predictions_buffer.append(is_violence)\n",
    "\n",
    "            # ðŸ“Œ Apply temporal smoothing: Majority voting within the buffer window\n",
    "            if sum(predictions_buffer) > len(predictions_buffer) / 2:\n",
    "                label = \"Violence\"\n",
    "                color = (0, 0, 255)  # Red for violence\n",
    "\n",
    "                # ðŸ“Œ Save the frame if it hasn't been saved before\n",
    "                if frame_count not in stored_frame_indices:\n",
    "                    stored_frame_indices.add(frame_count)\n",
    "\n",
    "                    # ðŸ“Œ Add text label before saving the image\n",
    "                    frame_with_label = frame.copy()\n",
    "                    cv2.putText(frame_with_label, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, color, 3)\n",
    "\n",
    "                    # ðŸ“Œ Save frame\n",
    "                    frame_filename = os.path.join(video_output_dir, f\"frame_{frame_count}.jpg\")\n",
    "                    cv2.imwrite(frame_filename, frame_with_label)\n",
    "                    \n",
    "            else:\n",
    "                label = \"No Violence\"\n",
    "                color = (0, 255, 0)  # Green for no violence\n",
    "\n",
    "            # ðŸ“Œ Remove the oldest frame from buffer (FIFO mechanism)\n",
    "            frame_buffer.pop(0)\n",
    "\n",
    "        # ðŸ“Œ Display the label on the frame\n",
    "        cv2.putText(frame, label, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, color, 3)\n",
    "\n",
    "        # ðŸ“Œ Show the live video feed with the detection label\n",
    "        cv2.imshow('Road Rage Detection', frame)\n",
    "\n",
    "        # ðŸ“Œ Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # ðŸ“Œ Release resources\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŽ¯ 4. Run Live Road Rage Detection on a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Paths and parameters\n",
    "video_path = 'sample2.mp4'  # Replace with your video path\n",
    "output_dir = 'Violent_Frames'  # Directory to store detected frames\n",
    "\n",
    "# ðŸ“Œ Start live road rage detection and save violence frames\n",
    "live_road_rage_detection(model, video_path, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
